{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting and Evaluating Models\n",
    "Based on the small number of variables and the fact that this is a regression problem, I decided to keep the models fairly simple. In the pairplots in the [EDA and cleaning notebook](./02_eda_and_cleaning.ipynb), I observed what appeared to be a polynomial relationship between the magnitudes in each band (U, G, R, I, Z) and the redshift, so I tested a polynomial regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "# import modules for preprocessing and modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies = pd.read_csv(\"../data/sdss_clean.csv\", index_col=False)\n",
    "# read in cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = galaxies[[\"u\", \"g\", \"r\", \"i\", \"z\"]]\n",
    "y = galaxies[\"redshift\"]\n",
    "# create feature matrix and target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=20200310)\n",
    "# split X and y into training and test sets for model fitting and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set baseline (RMSE): 0.2226269235953162\n",
      "Test set baseline (RMSE): 0.2244908042024483\n"
     ]
    }
   ],
   "source": [
    "y_train_mean = y_train.mean()\n",
    "y_train_baseline = list()\n",
    "for i in range(len(y_train)):\n",
    "    y_train_baseline.append(y_train_mean)\n",
    "\n",
    "y_test_mean = y_test.mean()\n",
    "y_test_baseline = list()\n",
    "for i in range(len(y_test)):\n",
    "    y_test_baseline.append(y_test_mean)\n",
    "\n",
    "baseline_train_rmse = np.sqrt(MSE(y_train, y_train_baseline))\n",
    "baseline_test_rmse = np.sqrt(MSE(y_test, y_test_baseline))\n",
    "\n",
    "print(f\"Training set baseline (RMSE): {baseline_train_rmse}\")\n",
    "print(f\"Test set baseline (RMSE): {baseline_test_rmse}\")\n",
    "# for both training and test set: obtain mean squared error for a model that predicts the mean of y for every observation, then take the square root\n",
    "# to obtain the RMSE and use this as the baseline score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train);\n",
    "# instantiate a linear regression and fit it to X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set r2 score: 0.8392073178821228\n",
      "Test set r2 score: 0.8315979055902201\n",
      "Training set RMSE: 0.08919968190914797\n",
      "Test set RMSE: 0.09201922483354388\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set r2 score: {cross_val_score(linreg, X_train, y_train).mean()}\")\n",
    "print(f\"Test set r2 score: {cross_val_score(linreg, X_test, y_test).mean()}\")\n",
    "print(f\"Training set RMSE: {np.sqrt(MSE(y_train, linreg.predict(X_train)))}\")\n",
    "print(f\"Test set RMSE: {np.sqrt(MSE(y_test, linreg.predict(X_test)))}\")\n",
    "# get the average R2 score on the training and test set using 5-fold cross validation as well as RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_poly = PolynomialFeatures(2)\n",
    "# instantiate a polynomial features transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_quad = quad_poly.fit_transform(X_train)\n",
    "X_test_quad = quad_poly.transform(X_test)\n",
    "# fit to and transform the training set features; transform the test set features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_2 = LinearRegression()\n",
    "linreg_2.fit(X_train_quad, y_train);\n",
    "# instantiate a new linear regression and fit it to the transformed training set features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set r2 score: 0.8577803027139433\n",
      "Test set r2 score: 0.8538380742950643\n",
      "Training set RMSE: 0.08318758776911535\n",
      "Test set RMSE: 0.0857170064855389\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set r2 score: {cross_val_score(linreg_2, X_train_quad, y_train).mean()}\")\n",
    "print(f\"Test set r2 score: {cross_val_score(linreg_2, X_test_quad, y_test).mean()}\")\n",
    "print(f\"Training set RMSE: {np.sqrt(MSE(y_train, linreg_2.predict(X_train_quad)))}\")\n",
    "print(f\"Test set RMSE: {np.sqrt(MSE(y_test, linreg_2.predict(X_test_quad)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cubic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_poly = PolynomialFeatures(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cube = cube_poly.fit_transform(X_train)\n",
    "X_test_cube = cube_poly.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_3 = LinearRegression()\n",
    "linreg_3.fit(X_train_cube, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set r2 score: 0.8033156511454067\n",
      "Test set r2 score: 0.8381467722433819\n",
      "Training set RMSE: 0.07914729674451988\n",
      "Test set RMSE: 0.084846273370319\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set r2 score: {cross_val_score(linreg_3, X_train_cube, y_train).mean()}\")\n",
    "print(f\"Test set r2 score: {cross_val_score(linreg_3, X_test_cube, y_test).mean()}\")\n",
    "print(f\"Training set RMSE: {np.sqrt(MSE(y_train, linreg_3.predict(X_train_cube)))}\")\n",
    "print(f\"Test set RMSE: {np.sqrt(MSE(y_test, linreg_3.predict(X_test_cube)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "21\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[1])\n",
    "print(X_train_quad.shape[1])\n",
    "print(X_train_cube.shape[1])\n",
    "# number of features used for linear, quadratic and cubic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe that the quadratic regression is the strongest of these three models. It outperformed the linear regression on both metrics; the cubic regression saw a very slight reduction in RMSE over the quadratic, but this was offset by a reduction in r<sup>2</sup> scores as well as a large increase in the number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# instantiate transformer to scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "# scale training set and test set features to enable KNN model to make good predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set R2 score: 0.8674301716149604\n",
      "Test set R2 score: 0.8518395208802725\n",
      "Training set RMSE: 0.06552448183077234\n",
      "Test set RMSE: 0.0823038157725722\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor()\n",
    "# instantiate KNN regression with default 5 neighbors used\n",
    "knn.fit(X_train_sc, y_train);\n",
    "print(f\"Training set R2 score: {cross_val_score(knn, X_train_sc, y_train).mean()}\")\n",
    "print(f\"Test set R2 score: {cross_val_score(knn, X_test_sc, y_test).mean()}\")\n",
    "print(f\"Training set RMSE: {np.sqrt(MSE(y_train, knn.predict(X_train_sc)))}\")\n",
    "print(f\"Test set RMSE: {np.sqrt(MSE(y_test, knn.predict(X_test_sc)))}\")\n",
    "# print r2 and RMSE on training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores = list()\n",
    "rmse = list()\n",
    "# empty lists to hold evaluation metrics for 30 KNN models\n",
    "\n",
    "for k in range(1, 31):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(X_train_sc, y_train);\n",
    "    r2_scores.append((cross_val_score(knn, X_test_sc, y_test).mean(), k))\n",
    "    rmse.append((np.sqrt(MSE(y_test, knn.predict(X_test_sc))), k))\n",
    "    # instantiate and fit 30 KNN models with k=1 to k=30 neighbors; put the scores and k values in the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores.sort(reverse=True)\n",
    "# sort r2 scores from highest to lowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse.sort()\n",
    "# sort RMSE values from lowest to highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8588578414486603, 10),\n",
       " (0.8588010539775712, 8),\n",
       " (0.8587968020869482, 12),\n",
       " (0.8587603754409912, 9),\n",
       " (0.8587461021559388, 16)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_scores[:5]\n",
    "# see 5 best r2 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.08003349292320475, 15),\n",
       " (0.08009857182535854, 14),\n",
       " (0.08010869826868235, 17),\n",
       " (0.08012373861161977, 16),\n",
       " (0.0801550811947784, 13)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse[:5]\n",
    "# see 5 best RMSE scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 16 appears in both the 5 highest r<sup>2</sup> scores and the 5 lowest RMSE values. The KNN model using 16 neighbors gave an r<sup>2</sup> score of 0.859 and an RMSE of 0.080 on the test set. This is a very slight improvement over the quadratic regression. The fact that no values above 17 show up in either of these lists suggests that 16 is the optimal number, or at least a good tradeoff between performance and training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(random_state=20200310)\n",
    "# instantiate random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_params = {\n",
    "    \"n_estimators\": [20, 30, 40],\n",
    "    \"max_depth\": [8, 9, 10],\n",
    "    \"min_samples_split\": [2, 10, 20]\n",
    "}\n",
    "# create dictionary of hyperparemeters for gridsearch\n",
    "# limit number of estimators to 40  and max depth to 10 to minimize overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(\n",
    "    estimator=rfr,\n",
    "    param_grid=rfr_params,\n",
    "    return_train_score=True,\n",
    "    n_jobs=6,\n",
    ")\n",
    "# instantiate gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(X_train, y_train);\n",
    "# run gridsearch to test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(gs.cv_results_)\n",
    "# create a DataFrame of the results from the gridsearch for ease of model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_max_depth', 'param_min_samples_split', 'param_n_estimators',\n",
       "       'params', 'split0_test_score', 'split1_test_score', 'split2_test_score',\n",
       "       'split3_test_score', 'split4_test_score', 'mean_test_score',\n",
       "       'std_test_score', 'rank_test_score', 'split0_train_score',\n",
       "       'split1_train_score', 'split2_train_score', 'split3_train_score',\n",
       "       'split4_train_score', 'mean_train_score', 'std_train_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.columns\n",
    "# see what information is needed for model selection and what can be left out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_results = results.drop(\n",
    "    columns=[\n",
    "        \"mean_fit_time\",\n",
    "        \"std_fit_time\",\n",
    "        \"mean_score_time\",\n",
    "        \"std_score_time\",\n",
    "        \"params\",\n",
    "        \"split0_test_score\",\n",
    "        \"split1_test_score\",\n",
    "        \"split2_test_score\",\n",
    "        \"split3_test_score\",\n",
    "        \"split4_test_score\",\n",
    "        \"std_test_score\",\n",
    "        \"split0_train_score\",\n",
    "        \"split1_train_score\",\n",
    "        \"split2_train_score\",\n",
    "        \"split3_train_score\",\n",
    "        \"split4_train_score\",\n",
    "        \"std_train_score\"\n",
    "    ])\n",
    "# drop the unnecessary columns and display the useful results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>0.879250</td>\n",
       "      <td>1</td>\n",
       "      <td>0.907124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0.879193</td>\n",
       "      <td>2</td>\n",
       "      <td>0.910157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.878965</td>\n",
       "      <td>3</td>\n",
       "      <td>0.907034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.878949</td>\n",
       "      <td>4</td>\n",
       "      <td>0.914200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.878913</td>\n",
       "      <td>5</td>\n",
       "      <td>0.910040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0.878502</td>\n",
       "      <td>6</td>\n",
       "      <td>0.914051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.878361</td>\n",
       "      <td>7</td>\n",
       "      <td>0.908932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.878293</td>\n",
       "      <td>8</td>\n",
       "      <td>0.906053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.877877</td>\n",
       "      <td>9</td>\n",
       "      <td>0.912810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>0.875082</td>\n",
       "      <td>10</td>\n",
       "      <td>0.897076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0.875008</td>\n",
       "      <td>11</td>\n",
       "      <td>0.898939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.874919</td>\n",
       "      <td>12</td>\n",
       "      <td>0.897012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.874867</td>\n",
       "      <td>13</td>\n",
       "      <td>0.901444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.874772</td>\n",
       "      <td>14</td>\n",
       "      <td>0.898876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0.874573</td>\n",
       "      <td>15</td>\n",
       "      <td>0.901389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.874185</td>\n",
       "      <td>16</td>\n",
       "      <td>0.896138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.874066</td>\n",
       "      <td>17</td>\n",
       "      <td>0.897926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.873938</td>\n",
       "      <td>18</td>\n",
       "      <td>0.900356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>0.868885</td>\n",
       "      <td>19</td>\n",
       "      <td>0.884963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0.868840</td>\n",
       "      <td>20</td>\n",
       "      <td>0.886087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.868796</td>\n",
       "      <td>21</td>\n",
       "      <td>0.884917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.868778</td>\n",
       "      <td>22</td>\n",
       "      <td>0.887591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.868717</td>\n",
       "      <td>23</td>\n",
       "      <td>0.886011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0.868615</td>\n",
       "      <td>24</td>\n",
       "      <td>0.887532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.868109</td>\n",
       "      <td>25</td>\n",
       "      <td>0.885175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.868064</td>\n",
       "      <td>26</td>\n",
       "      <td>0.884119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.867988</td>\n",
       "      <td>27</td>\n",
       "      <td>0.886621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_max_depth param_min_samples_split param_n_estimators  \\\n",
       "26              10                      20                 40   \n",
       "23              10                      10                 40   \n",
       "25              10                      20                 30   \n",
       "20              10                       2                 40   \n",
       "22              10                      10                 30   \n",
       "19              10                       2                 30   \n",
       "21              10                      10                 20   \n",
       "24              10                      20                 20   \n",
       "18              10                       2                 20   \n",
       "17               9                      20                 40   \n",
       "14               9                      10                 40   \n",
       "16               9                      20                 30   \n",
       "11               9                       2                 40   \n",
       "13               9                      10                 30   \n",
       "10               9                       2                 30   \n",
       "15               9                      20                 20   \n",
       "12               9                      10                 20   \n",
       "9                9                       2                 20   \n",
       "8                8                      20                 40   \n",
       "5                8                      10                 40   \n",
       "7                8                      20                 30   \n",
       "2                8                       2                 40   \n",
       "4                8                      10                 30   \n",
       "1                8                       2                 30   \n",
       "3                8                      10                 20   \n",
       "6                8                      20                 20   \n",
       "0                8                       2                 20   \n",
       "\n",
       "    mean_test_score  rank_test_score  mean_train_score  \n",
       "26         0.879250                1          0.907124  \n",
       "23         0.879193                2          0.910157  \n",
       "25         0.878965                3          0.907034  \n",
       "20         0.878949                4          0.914200  \n",
       "22         0.878913                5          0.910040  \n",
       "19         0.878502                6          0.914051  \n",
       "21         0.878361                7          0.908932  \n",
       "24         0.878293                8          0.906053  \n",
       "18         0.877877                9          0.912810  \n",
       "17         0.875082               10          0.897076  \n",
       "14         0.875008               11          0.898939  \n",
       "16         0.874919               12          0.897012  \n",
       "11         0.874867               13          0.901444  \n",
       "13         0.874772               14          0.898876  \n",
       "10         0.874573               15          0.901389  \n",
       "15         0.874185               16          0.896138  \n",
       "12         0.874066               17          0.897926  \n",
       "9          0.873938               18          0.900356  \n",
       "8          0.868885               19          0.884963  \n",
       "5          0.868840               20          0.886087  \n",
       "7          0.868796               21          0.884917  \n",
       "2          0.868778               22          0.887591  \n",
       "4          0.868717               23          0.886011  \n",
       "1          0.868615               24          0.887532  \n",
       "3          0.868109               25          0.885175  \n",
       "6          0.868064               26          0.884119  \n",
       "0          0.867988               27          0.886621  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_results.sort_values(by=\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these results, it is worth running another gridsearch with larger values for min_samples_split while still limiting max_depth to 10 and n_estimators to 40 to control overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(random_state=20200310)\n",
    "rfr_params = {\n",
    "    \"n_estimators\": [40],\n",
    "    \"max_depth\": [10],\n",
    "    \"min_samples_split\": list(range(10, 110, 10))\n",
    "}\n",
    "gs = GridSearchCV(\n",
    "    estimator=rfr,\n",
    "    param_grid=rfr_params,\n",
    "    return_train_score=True,\n",
    "    n_jobs=6,\n",
    ")\n",
    "gs.fit(X_train, y_train);\n",
    "# instantiate and run another gridsearch with the new hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0.879193</td>\n",
       "      <td>2</td>\n",
       "      <td>0.910157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>0.879250</td>\n",
       "      <td>1</td>\n",
       "      <td>0.907124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>0.879032</td>\n",
       "      <td>3</td>\n",
       "      <td>0.905125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>0.878843</td>\n",
       "      <td>4</td>\n",
       "      <td>0.903404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>0.878486</td>\n",
       "      <td>5</td>\n",
       "      <td>0.901840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>0.878295</td>\n",
       "      <td>6</td>\n",
       "      <td>0.900350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>0.877906</td>\n",
       "      <td>7</td>\n",
       "      <td>0.898924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>0.877590</td>\n",
       "      <td>8</td>\n",
       "      <td>0.897725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>0.877137</td>\n",
       "      <td>9</td>\n",
       "      <td>0.896466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>0.876829</td>\n",
       "      <td>10</td>\n",
       "      <td>0.895444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_max_depth param_min_samples_split param_n_estimators  mean_test_score  \\\n",
       "0              10                      10                 40         0.879193   \n",
       "1              10                      20                 40         0.879250   \n",
       "2              10                      30                 40         0.879032   \n",
       "3              10                      40                 40         0.878843   \n",
       "4              10                      50                 40         0.878486   \n",
       "5              10                      60                 40         0.878295   \n",
       "6              10                      70                 40         0.877906   \n",
       "7              10                      80                 40         0.877590   \n",
       "8              10                      90                 40         0.877137   \n",
       "9              10                     100                 40         0.876829   \n",
       "\n",
       "   rank_test_score  mean_train_score  \n",
       "0                2          0.910157  \n",
       "1                1          0.907124  \n",
       "2                3          0.905125  \n",
       "3                4          0.903404  \n",
       "4                5          0.901840  \n",
       "5                6          0.900350  \n",
       "6                7          0.898924  \n",
       "7                8          0.897725  \n",
       "8                9          0.896466  \n",
       "9               10          0.895444  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(gs.cv_results_)\n",
    "reduced_results = results.drop(\n",
    "    columns=[\n",
    "        \"mean_fit_time\",\n",
    "        \"std_fit_time\",\n",
    "        \"mean_score_time\",\n",
    "        \"std_score_time\",\n",
    "        \"params\",\n",
    "        \"split0_test_score\",\n",
    "        \"split1_test_score\",\n",
    "        \"split2_test_score\",\n",
    "        \"split3_test_score\",\n",
    "        \"split4_test_score\",\n",
    "        \"std_test_score\",\n",
    "        \"split0_train_score\",\n",
    "        \"split1_train_score\",\n",
    "        \"split2_train_score\",\n",
    "        \"split3_train_score\",\n",
    "        \"split4_train_score\",\n",
    "        \"std_train_score\"\n",
    "    ])\n",
    "reduced_results\n",
    "# display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = RandomForestRegressor(n_estimators=40, max_depth=10, min_samples_split=20, n_jobs=6, random_state=20200310)\n",
    "final_model.fit(X_train, y_train);\n",
    "# train a random forest model with the optimal hyperparameters on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0797164356820923"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(MSE(y_test, final_model.predict(X_test)))\n",
    "# obtain RMSE for the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
